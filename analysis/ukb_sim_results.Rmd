---
title: "Simulations with UK Biobank genotypes and different effect structure across traits"
author: "Fabio Morgante & Deborah Kunkel"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  workflowr::wflow_html:
    toc: true
editor_options:
  chunk_output_type: console
---

```{r set options}
###Load libraries
library(ggplot2)
library(cowplot)

repz <- 1:20
prefix <- "output/prediction_accuracy/ukb_caucasian_white_british_unrel_100000"
metric <- "r2"
traitz <- 1:5
```

## Introduction

The goal of this analysis is to benchmark the newly developed *mr.mash.rss* (aka *mr.mash* with summary 
data) against already existing methods in the task of predicting phenotypes from genotypes using 
only summary data. To do so, we used real genotypes from the array data of the UK Biobank. We randomly 
sampled 105,000 nominally unrelated ($r_A$ < 0.025 between any pair) individuals of European ancestry 
(i.e., Caucasian and white British fields). After retaining variants with minor allele frequency 
(MAF) > 0.01, minor allele count (MAC) > 5, genotype missing rate < 0.1 and Hardy-Weinberg Equilibrium (HWE) 
test p-value > $1 *10^{-10}$, our data consisted of 595,071 genetic variants (i.e., our predictors). 
Missing genotypes were imputed with the mean genotype for the respective genetic variant.

The linkage disequilibrium (LD) matrices (i.e., the correlation matrices) were computed using 146,288 
nominally unrelated ($r_A$ < 0.025 between any pair) individuals of European ancestry (i.e., Caucasian 
and white British fields), that did not overlap with the 105,000 individuals used for the rest of the analyses.

For each replicate, we simulated 5 traits (i.e., our responses) by randomly sampling 5,000 variants 
(out of the total of 595,071) to be causal, with different effect sharing structures across traits (see below). 
The genetic effects explain 50\% of the total per-trait variance -- in genetics terminology this is called
genomic heritability ($h_g^2$). The residuals are uncorrelated across traits.

We randomly sampled 5,000 (out of the 105,000) individuals to be the test set. The test set was only used to 
evaluate prediction accuracy. All the other steps were carried out on the training set of 100,000 individuals.

Summary statistics (i.e., effect size and its standard error) were obtained by univariate simple linear 
regression of each trait on each variant, one at a time. Traits and variants were not standardized.

Three different methods were fitted:

* [LDpred2](https://academic.oup.com/bioinformatics/article/36/22-23/5424/6039173) per-chromosome with 
the auto option, 500 iterations (after 500 burn-in iterations), $h^2$ initialized as 0.5/22 and $p$ 
initialized using the same grid as in the original paper. NB this is a univariate method.
* _LDpred2_ genome-wide with the auto option, 500 iterations (after 500 burn-in iterations), $h^2$ 
initialized as 0.5/22 (WRONG) and $p$ initialized using the same grid as in the original paper.
NB this is a univariate method.
* _mr.mash.rss_ per-chromosome, with both canonical and data-driven covariance matrices computed 
as described in the [mr.mash paper](https://www.biorxiv.org/content/10.1101/2022.11.22.517471v4.abstract),
updating the (full rank) residual covariance and the mixture weights, without standardizing the variables. 
The residual covariance was initialized as in the [mvSuSiE paper](https://www.biorxiv.org/content/10.1101/2023.04.14.536893v1)
and the mixture weights were initialized as 90\% of the weight on the null component and 10\% of the
weight split equally across the remaining components. The phenotypic covariance was computed
as the sample covariance using the individual-level data. NB this is a multivariate method.

Prediction accuracy was evaluated as the $R^2$ of the regression of true phenotypes on the predicted 
phenotypes. This metric as the attractive property that its upper bound is $h_g^2$.

20 replicates for each simulation scenario were run.

## Equal effects scenario

In this scenario, the effects were drawn from a Multivariate Normal distribution with mean vector 0
and covariance matrix that achieves a per-trait variance of 1 and a correlation across traits of 1.
This implies that the effects of the causal variants are equal across responses.

```{r equal effects, fig.height=10, fig.width=13}
scenarioz <- "equal_effects_indep_resid"
methodz <- c("mr_mash_rss", "ldpred2_auto", "ldpred2_auto_gwide")

i <- 0

n_col <- 6
n_row <- length(repz) * length(scenarioz) * length(methodz) * length(traitz)
res <- as.data.frame(matrix(NA, ncol=n_col, nrow=n_row))
colnames(res) <- c("rep", "scenario", "method", "trait", "metric", "score")

for(sce in scenarioz){
  for(met in methodz){
    for(repp in repz){
      dat <- readRDS(paste0(prefix, "_", sce, "_", met, "_pred_acc_", repp, ".rds"))
      
      for(trait in traitz){
        i <- i + 1
        
        res[i, 1] <- repp
        res[i, 2] <- sce
        res[i, 3] <- met
        res[i, 4] <- trait
        res[i, 5] <- metric
        res[i, 6] <- dat$r2[trait]
      }
    }
  }
}

res <- transform(res, scenario=as.factor(scenario),
                      method=as.factor(method),
                      trait=as.factor(trait))

p_methods_shared <- ggplot(res, aes(x = trait, y = score, fill = method)) +
  geom_boxplot(color = "black", outlier.size = 1, width = 0.85) +
  stat_summary(fun=mean, geom="point", shape=23,
               position = position_dodge2(width = 0.87,   
                                          preserve = "single")) +
  ylim(0.3, 0.51) +
  scale_fill_manual(values = c("pink", "red", "green")) +
  labs(x = "Trait", y = expression(italic(R)^2), fill="Method", title="") +
  geom_hline(yintercept=0.5, linetype="dotted", linewidth=1, color = "black") +
  theme_cowplot(font_size = 18)

print(p_methods_shared)
```

In this scenario, there is a clear advantage to using multivariate methods. In fact, given
that the effects are equal across traits and the residuals are uncorrelated, a multivariate
analysis is roughly equivalent to having 5 times as many samples as in an univariate
analysis. The results show that *mr.mash.rss* clearly does better than both flavors of 
*LDpred2 auto*. However, in this simulation there does not seem to be much of a difference 
between *LDpred2 auto* per-chromosome and genome-wide. Therefore, we will drop *LDpred2 auto* 
genome-wide from further analyses since it is more computationally intensive.

## Mostly null scenario

In this scenario, the effects were drawn from a Multivariate Normal distribution with mean vector 0
and covariance matrix that achieves effects (with variance 1) to be present only trait 1. The other 
4 traits are only random noise.

```{r mostly null, fig.height=10, fig.width=13}
scenarioz <- "trait_1_only_effects_indep_resid"
methodz <- c("mr_mash_rss", "ldpred2_auto")

i <- 0

n_col <- 6
n_row <- length(repz) * length(scenarioz) * length(methodz) * length(traitz)
res <- as.data.frame(matrix(NA, ncol=n_col, nrow=n_row))
colnames(res) <- c("rep", "scenario", "method", "trait", "metric", "score")

for(sce in scenarioz){
  for(met in methodz){
    for(repp in repz){
      dat <- readRDS(paste0(prefix, "_", sce, "_", met, "_pred_acc_", repp, ".rds"))
      
      for(trait in traitz){
        i <- i + 1
        
        res[i, 1] <- repp
        res[i, 2] <- sce
        res[i, 3] <- met
        res[i, 4] <- trait
        res[i, 5] <- metric
        res[i, 6] <- dat$r2[trait]
      }
    }
  }
}

res <- transform(res, scenario=as.factor(scenario),
                      method=as.factor(method),
                      trait=as.factor(trait))

p_mostly_null <- ggplot(res, aes(x = trait, y = score, fill = method)) +
  geom_boxplot(color = "black", outlier.size = 1, width = 0.85) +
  stat_summary(fun=mean, geom="point", shape=23,
               position = position_dodge2(width = 0.87,   
                                          preserve = "single")) +
  ylim(0.0, 0.51) +
  scale_fill_manual(values = c("pink", "green")) +
  labs(x = "Trait", y = expression(italic(R)^2), fill="Method", title="") +
  geom_hline(yintercept=0.5, linetype="dotted", linewidth=1, color = "black") +
  theme_cowplot(font_size = 18)

print(p_mostly_null)
```

In this scenario, there is no advantage to using multivariate methods. In fact, there is potential
for multivariate methods to do worse than univariate methods because of the large amount of noise
modeled jointly with the signal. However, the results show that *mr.mash.rss* can learn this structure
from the data and, reassuringly, performs similarly to *LDpred2 auto*.

## Shared in subgroups scenario

In this scenario, the effects were drawn from a mixture of two Multivariate Normal distributions, i.e., 
$w_1 MVN(0, \Sigma_1) + w_2 MVN(0, \Sigma_2)$, where $w_1$ = 0.5 and $w_2$ = 0.5. $\Sigma_1$ is such 
that it achieves correlation across traits of 0.9 and variance of 1. $\Sigma_2$ is such that it achieves 
correlation across traits of 0.7 and variance of 1. The first component of the mixture applies to traits 1-3
while the second component applies to traits 4-5. The per-trait $h^2_g$ is 0.3 for traits 1-3 and 0.5 for the
traits 4-5.

```{r shared in subgroups, fig.height=10, fig.width=13}
scenarioz <- "blocks_shared_effects_indep_resid"
methodz <- c("mr_mash_rss", "ldpred2_auto")

i <- 0

n_col <- 6
n_row <- length(repz) * length(scenarioz) * length(methodz) * length(traitz)
res <- as.data.frame(matrix(NA, ncol=n_col, nrow=n_row))
colnames(res) <- c("rep", "scenario", "method", "trait", "metric", "score")

for(sce in scenarioz){
  for(met in methodz){
    for(repp in repz){
      dat <- readRDS(paste0(prefix, "_", sce, "_", met, "_pred_acc_", repp, ".rds"))
      
      for(trait in traitz){
        i <- i + 1
        
        res[i, 1] <- repp
        res[i, 2] <- sce
        res[i, 3] <- met
        res[i, 4] <- trait
        res[i, 5] <- metric
        res[i, 6] <- dat$r2[trait]
      }
    }
  }
}

res <- transform(res, scenario=as.factor(scenario),
                      method=as.factor(method),
                      trait=as.factor(trait))

p_blocks_shared <- ggplot(res, aes(x = trait, y = score, fill = method)) +
  geom_boxplot(color = "black", outlier.size = 1, width = 0.85) +
  stat_summary(fun=mean, geom="point", shape=23,
               position = position_dodge2(width = 0.87,   
                                          preserve = "single")) +
  ylim(0.1, 0.51) +
  scale_fill_manual(values = c("pink", "green")) +
  labs(x = "Trait", y = expression(italic(R)^2), fill="Method", title="") +
  geom_hline(yintercept=0.5, linetype="dotted", linewidth=1, color = "black") +
  geom_hline(yintercept=0.5, linetype="dashed", linewidth=1, color = "black") +
  theme_cowplot(font_size = 18)

print(p_blocks_shared)
```

In this scenario, multivariate methods can have some advantage over univariate methods, provided that
the former can adapt to the complex structure of the effects. The results show that *mr.mash.rss* does
better than *LDpred2 auto* across all the traits. However, the improvement is more evident in traits 1-3,
due to the higher effect correlation across traits, the larger number of traits with shared effects, and
the smaller $h^2_g$ (harder scenario for univariate methods).
